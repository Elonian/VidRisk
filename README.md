# VidRisk

##  Evaluating Video Classifocation Model Susceptibility

In recent years, convolutional neural networks (CNNs) have been copiously applied in various image recogni- tion and processing problems giving state-of-the-art results close to the human-level performance. However, their per- formance is challenged by the emergence of adversarial ma- chine learning techniques, which could launch powerful at- tacks on state-of-the-art models. Our work explores the field of classification of videos using deep learning models. We alos explore the vulnerabilty of video classification models for single-frame image noises which is an ascept of elec- tronic noise. We will try to design adversarial attacks at the frame level and observe the susceptibility of models.
